{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FIi8t8NUTEJ"
   },
   "source": [
    "# Time Series Prediction with RNN/LSTM/GRU Using PyTorch\n",
    "\n",
    "In this notebook you will implememt RNN, LSTM and GRU models in order to predict future sales of Migros. Sales for Fruits and Vegetables are given for 2014-2017. You will train your model with 2014-2016 data and test on 2017 to see whether forecasting is done accurately.\n",
    "\n",
    "There are some tutorials on Time Series Prediction, you can get help from them: \n",
    "https://towardsdatascience.com/predicting-sales-611cb5a252de\n",
    "\n",
    "If you did not use pandas library before you can check this tutorial: \n",
    "https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSItPJipBaZ5"
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wb-Z7wNKUJko"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta,date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e31mswiSBEEB"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_length,\n",
    "        path,\n",
    "        mode='char',\n",
    "    ):\n",
    "        self.seq_length = seq_length\n",
    "        self.mode = mode\n",
    "        self.path = path\n",
    "        self.data = self._read_data()\n",
    "        \n",
    "        self.unique_data = self._find_unique()\n",
    "\n",
    "        self.index_to_data = {index: word for index, word in enumerate(self.unique_data)}\n",
    "        self.data_to_index = {word: index for index, word in enumerate(self.unique_data)}\n",
    "\n",
    "        self.data_indexes = [self.data_to_index[i] for i in self.data]\n",
    "\n",
    "    def _read_data(self):\n",
    "        text = open(self.path, 'rb').read().decode(encoding='utf-8')\n",
    "        data = pd.Series(list(re.sub(\"[\" + '\\n\\r\\ufeff' + \"]\", '', text))) if self.mode =='char' \\\n",
    "                    else pd.Series(re.findall(r\"[\\w']+|[.,!?;]\", text.lower()))\n",
    "        return data\n",
    "\n",
    "    def _find_unique(self):\n",
    "        data_count = Counter(self.data)\n",
    "        return sorted(data_count, key=data_count.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_indexes) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.data_indexes[idx:idx+self.seq_length]),\n",
    "            torch.tensor(self.data_indexes[idx+1:idx+self.seq_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(100, 'data/pride_prejudice.txt', 'word')\n",
    "dataloader = DataLoader(dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('data/pride_prejudice.txt', 'rb').read().decode(encoding='utf-8')\n",
    "data = pd.Series(re.findall(r\"[\\w']+|[.,!?;]\", text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               the\n",
       "1           project\n",
       "2         gutenberg\n",
       "3             ebook\n",
       "4                of\n",
       "            ...    \n",
       "144392         hear\n",
       "144393        about\n",
       "144394          new\n",
       "144395       ebooks\n",
       "144396            .\n",
       "Length: 144397, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, LSTM and GRU\n",
    "\n",
    "For each model train and test models with both Fruit and Vegetables data and plot the results. Also give MAPE results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--1LVbHOBSIy"
   },
   "source": [
    "## Recurrent Neural Network (RNN) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=3, seq_length=20):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length \n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_size,\n",
    "            embedding_dim=self.hidden_size,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.hidden_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, input_size)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, *prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def initialize(self):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "a2vvHeFgVtCp",
    "outputId": "5fa2cd4c-dcc4-41aa-d7bc-cb16154ff134"
   },
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = dataset.\n",
    "\n",
    "model = RNN_Model(input_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "jFrPVG5sesWY",
    "outputId": "080fecbc-7cec-496d-e753-01371109f123"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "train_predict = model(testX)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = testY.data.numpy()\n",
    "\n",
    "data_predict = scaler.inverse_transform(data_predict)\n",
    "dataY_plot = scaler.inverse_transform(dataY_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot actual and predicted\n",
    "plot_data = [\n",
    "    go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=dataY_plot.flatten(),\n",
    "        name='actual'\n",
    "    ),\n",
    "        go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=data_predict.flatten(),\n",
    "        name='predicted'\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "plot_layout = go.Layout(\n",
    "        title='Sales Prediction'\n",
    "    )\n",
    "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "pyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short Term Memory (LSTM) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BcDEjcABRVz"
   },
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "model = LSTM_Model(input_size, hidden_size, num_layers, seq_length)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "train_predict = model(testX)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = testY.data.numpy()\n",
    "\n",
    "data_predict = scaler.inverse_transform(data_predict)\n",
    "dataY_plot = scaler.inverse_transform(dataY_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot actual and predicted\n",
    "plot_data = [\n",
    "    go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=dataY_plot.flatten(),\n",
    "        name='actual'\n",
    "    ),\n",
    "        go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=data_predict.flatten(),\n",
    "        name='predicted'\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "plot_layout = go.Layout(\n",
    "        title='Sales Prediction'\n",
    "    )\n",
    "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "pyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Recurrent Unit (GRU) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(GRU_Model, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "\n",
    "model = LSTM_Model(input_size, hidden_size, num_layers, seq_length)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "train_predict = model(testX)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = testY.data.numpy()\n",
    "\n",
    "data_predict = scaler.inverse_transform(data_predict)\n",
    "dataY_plot = scaler.inverse_transform(dataY_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot actual and predicted\n",
    "plot_data = [\n",
    "    go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=dataY_plot.flatten(),\n",
    "        name='actual'\n",
    "    ),\n",
    "        go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=data_predict.flatten(),\n",
    "        name='predicted'\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "plot_layout = go.Layout(\n",
    "        title='Sales Prediction'\n",
    "    )\n",
    "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "pyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Design (25 points)\n",
    "\n",
    "In the sections above you have only used previous sales as features. Try adding different features such as temperature, dolar exchange rate, month(categorical), day of week(categorical), some special days (such as religious holidays, valentine's day, new year's day).\n",
    "\n",
    "Then design a new model to train and test with these features. Try to reduce **MAPE** metric below to previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv('data/net_sales.txt',sep='\\t', header = (0))\n",
    "\n",
    "# Design your features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Train and Test Your Model for New Designed Features (25 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change hyperparameters\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "model = Model(input_size, hidden_size, num_layers, seq_length)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot actual and predicted\n",
    "plot_data = [\n",
    "    go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=dataY_plot.flatten(),\n",
    "        name='actual'\n",
    "    ),\n",
    "        go.Scatter(\n",
    "        x=df_sales['Tarih'][-365:],\n",
    "        y=data_predict.flatten(),\n",
    "        name='predicted'\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "plot_layout = go.Layout(\n",
    "        title='Sales Prediction'\n",
    "    )\n",
    "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "pyoff.iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Time Series Prediction with LSTM Using PyTorch",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
