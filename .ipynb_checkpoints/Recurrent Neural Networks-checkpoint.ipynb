{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLG561E Assignment 4.1: Recurrent Neural Networks\n",
    "\n",
    "\n",
    "In this assignment, we will use the same API as in Assignment 1. You have implemented most of the required layers. You will add RNN layer under `./layers/layers_with_weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blg561.layer.recurrent_layers import RNNLayer, LSTMLayer, GRULayer\n",
    "from blg561.checks import rel_error, grad_check\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Layer: Forward Step (5 points)\n",
    "First implement and call the forward step for the RNN layer in RNNLayer class, and check the error rates whether below or 1e-6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_h error:  6.292421426471037e-09\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 3, 10, 4\n",
    "rnn = RNNLayer(10, 4)\n",
    "x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)\n",
    "rnn.Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)\n",
    "rnn.Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)\n",
    "rnn.b = np.linspace(-0.2, 0.4, num=H)\n",
    "\n",
    "next_h, _ = rnn.forward_step(x, prev_h)\n",
    "expected_next_h = np.array([\n",
    "  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "print('next_h error: ', rel_error(expected_next_h, next_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Forward Pass (5 points)\n",
    "Now, under RNNLayer, implement the forward method. It processes whole series. i.e. all time points in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h error:  3.533790822429694e-08\n"
     ]
    }
   ],
   "source": [
    "N, T, D, H = 2, 3, 4, 5\n",
    "rnn = RNNLayer(4,5)\n",
    "x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D)\n",
    "prev_h = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)\n",
    "rnn.Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)\n",
    "rnn.Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)\n",
    "rnn.b = np.linspace(-0.7, 0.1, num=H)\n",
    "\n",
    "h = rnn.forward(x, prev_h)\n",
    "expected_h = np.array([\n",
    "  [\n",
    "    [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],\n",
    "    [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],\n",
    "    [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],\n",
    "  ],\n",
    "  [\n",
    "    [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],\n",
    "    [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],\n",
    "    [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])\n",
    "print('h error: ', rel_error(expected_h[0], h[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Layer: Backward Step (5 points)\n",
    "First implement and call the backward step for the RNN layer in RNNLayer class, and check the error rates to see whether they are below or 1e-6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  2.723910994766152e-10\n",
      "dprev_h error:  8.071458495454475e-11\n",
      "dWx error:  4.626940825891975e-09\n",
      "dWh error:  1.8425923929720007e-08\n",
      "db error:  1.017319972407888e-07\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(145)\n",
    "N, D, H = 3, 10, 5\n",
    "rnn = RNNLayer(D, H)\n",
    "\n",
    "x = np.random.randn(N, D)\n",
    "prev_h = np.random.randn(N, H)\n",
    "rnn.Wx = np.random.randn(D, H)\n",
    "rnn.Wh = np.random.randn(H, H)\n",
    "rnn.b = np.random.randn(H)\n",
    "\n",
    "out, cache = rnn.forward_step(x, prev_h)\n",
    "\n",
    "dnext_h = np.linspace(-0.2, 0.4, num=N*H).reshape(N, H)\n",
    "\n",
    "dx, dprev_h, dWx, dWh, db = rnn.backward_step(dnext_h, cache)\n",
    "f = lambda _: rnn.forward_step(x, prev_h)[0]\n",
    "\n",
    "\n",
    "dx_num = grad_check(f, x, dnext_h)\n",
    "dprev_h_num = grad_check(f, prev_h, dnext_h)\n",
    "dWx_num = grad_check(f, rnn.Wx, dnext_h)\n",
    "dWh_num = grad_check(f, rnn.Wh, dnext_h)\n",
    "db_num = grad_check(f, rnn.b, dnext_h)\n",
    "\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dprev_h error: ', rel_error(dprev_h_num, dprev_h))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLayer: Backward Pass (5 points)\n",
    "Now, under RNNLayer, implement the backward method. It processes whole series. i.e. all time points in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  9.917285336838466e-09\n",
      "dh0 error:  3.1559256132370643e-08\n",
      "dWx error:  1.5848646622064045e-08\n",
      "dWh error:  8.00342854473065e-10\n",
      "db error:  1.02770223882174e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(145)\n",
    "\n",
    "N, D, T, H = 3, 10, 7, 5\n",
    "rnn = RNNLayer(D, H)\n",
    "\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "rnn.Wx = np.random.randn(D, H)\n",
    "rnn.Wh = np.random.randn(H, H)\n",
    "rnn.b = np.random.randn(H)\n",
    "\n",
    "out = rnn.forward(x, h0)\n",
    "\n",
    "dnext_h = np.random.randn(*out.shape)\n",
    "\n",
    "rnn.backward(dnext_h)\n",
    "\n",
    "dx, dh0, dWx, dWh, db = rnn.grad['dx'], rnn.grad['dh0'], rnn.grad['dWx'], rnn.grad['dWh'], rnn.grad['db']\n",
    "\n",
    "f = lambda _: rnn.forward(x, h0)\n",
    "\n",
    "dx_num = grad_check(f, x, dnext_h)\n",
    "dh0_num = grad_check(f, h0, dnext_h)\n",
    "dWx_num = grad_check(f, rnn.Wx, dnext_h)\n",
    "dWh_num = grad_check(f, rnn.Wh, dnext_h)\n",
    "db_num = grad_check(f, rnn.b, dnext_h)\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dh0 error: ', rel_error(dh0_num, dh0))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMLayer: Forward step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_h error:  5.7054131185818695e-09\n",
      "next_c error:  5.8143123088804145e-09\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 3, 4, 5\n",
    "lstm = LSTMLayer(4, 5)\n",
    "x = np.linspace(-0.4, 1.2, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.3, 0.7, num=N*H).reshape(N, H)\n",
    "prev_c = np.linspace(-0.4, 0.9, num=N*H).reshape(N, H)\n",
    "lstm.Wx = np.linspace(-2.1, 1.3, num=4*D*H).reshape(D, 4 * H)\n",
    "lstm.Wh = np.linspace(-0.7, 2.2, num=4*H*H).reshape(H, 4 * H)\n",
    "lstm.b = np.linspace(0.3, 0.7, num=4*H)\n",
    "\n",
    "next_h, next_c, _ = lstm.forward_step(x, prev_h, prev_c)\n",
    "\n",
    "expected_next_h = np.asarray([\n",
    "    [ 0.24635157,  0.28610883,  0.32240467,  0.35525807,  0.38474904],\n",
    "    [ 0.49223563,  0.55611431,  0.61507696,  0.66844003,  0.7159181 ],\n",
    "    [ 0.56735664,  0.66310127,  0.74419266,  0.80889665,  0.858299  ]])\n",
    "expected_next_c = np.asarray([\n",
    "    [ 0.32986176,  0.39145139,  0.451556,    0.51014116,  0.56717407],\n",
    "    [ 0.66382255,  0.76674007,  0.87195994,  0.97902709,  1.08751345],\n",
    "    [ 0.74192008,  0.90592151,  1.07717006,  1.25120233,  1.42395676]])\n",
    "\n",
    "print('next_h error: ', rel_error(expected_next_h, next_h))\n",
    "print('next_c error: ', rel_error(expected_next_c, next_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMLayer: Forward Pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h error:  8.610537452106624e-08\n"
     ]
    }
   ],
   "source": [
    "N, D, H, T = 2, 5, 4, 3\n",
    "lstm = LSTMLayer(5, 4)\n",
    "x = np.linspace(-0.4, 0.6, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.4, 0.8, num=N*H).reshape(N, H)\n",
    "lstm.Wx = np.linspace(-0.2, 0.9, num=4*D*H).reshape(D, 4 * H)\n",
    "lstm.Wh = np.linspace(-0.3, 0.6, num=4*H*H).reshape(H, 4 * H)\n",
    "lstm.b = np.linspace(0.2, 0.7, num=4*H)\n",
    "\n",
    "h = lstm.forward(x, h0)\n",
    "\n",
    "expected_h = np.asarray([\n",
    " [[ 0.01764008,  0.01823233,  0.01882671,  0.0194232 ],\n",
    "  [ 0.11287491,  0.12146228,  0.13018446,  0.13902939],\n",
    "  [ 0.31358768,  0.33338627,  0.35304453,  0.37250975]],\n",
    " [[ 0.45767879,  0.4761092,   0.4936887,   0.51041945],\n",
    "  [ 0.6704845,   0.69350089,  0.71486014,  0.7346449 ],\n",
    "  [ 0.81733511,  0.83677871,  0.85403753,  0.86935314]]])\n",
    "\n",
    "print('h error: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMLayer: Backward step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  1.2656949129307126e-10\n",
      "dprev_h error:  4.741560365192824e-09\n",
      "dprev_c error:  1.5406361137541342e-09\n",
      "dWx error:  6.49038639105056e-08\n",
      "dWh error:  1.4351961348358965e-08\n",
      "db error:  9.819004086843487e-09\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(132)\n",
    "\n",
    "N, D, H = 4, 5, 6\n",
    "lstm = LSTMLayer(5, 6)\n",
    "x = np.random.randn(N, D)\n",
    "prev_h = np.random.randn(N, H)\n",
    "prev_c = np.random.randn(N, H)\n",
    "lstm.Wx = np.random.randn(D, 4 * H)\n",
    "lstm.Wh = np.random.randn(H, 4 * H)\n",
    "lstm.b = np.random.randn(4 * H)\n",
    "\n",
    "next_h, next_c, cache = lstm.forward_step(x, prev_h, prev_c)\n",
    "\n",
    "dnext_h = np.random.randn(*next_h.shape)\n",
    "dnext_c = np.random.randn(*next_c.shape)\n",
    "\n",
    "f_h = lambda _: lstm.forward_step(x, prev_h, prev_c)[0]\n",
    "f_c = lambda _: lstm.forward_step(x, prev_h, prev_c)[1]\n",
    "\n",
    "dx_num = grad_check(f_h, x, dnext_h) + grad_check(f_c, x, dnext_c)\n",
    "dprev_h_num = grad_check(f_h, prev_h, dnext_h) + grad_check(f_c, prev_h, dnext_c)\n",
    "dprev_c_num = grad_check(f_h, prev_c, dnext_h) + grad_check(f_c, prev_c, dnext_c)\n",
    "dWx_num = grad_check(f_h, lstm.Wx, dnext_h) + grad_check(f_c, lstm.Wx, dnext_c)\n",
    "dWh_num = grad_check(f_h, lstm.Wh, dnext_h) + grad_check(f_c, lstm.Wh, dnext_c)\n",
    "db_num = grad_check(f_h, lstm.b, dnext_h) + grad_check(f_c, lstm.b, dnext_c)\n",
    "\n",
    "dx, dh, dc, dWx, dWh, db = lstm.backward_step(dnext_h, dnext_c, cache)\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dprev_h error: ', rel_error(dprev_h_num, dh))\n",
    "print('dprev_c error: ', rel_error(dprev_c_num, dc))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMLayer: Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-05979df2b38d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdnext_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dh0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dWx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dWh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'db'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dout' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 6\n",
    "\n",
    "lstm = LSTMLayer(3, 6)\n",
    "\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "lstm.Wx = np.random.randn(D, 4 * H)\n",
    "lstm.Wh = np.random.randn(H, 4 * H)\n",
    "lstm.b = np.random.randn(4 * H)\n",
    "\n",
    "out = lstm.forward(x, h0)\n",
    "\n",
    "dnext_h = np.random.randn(*out.shape)\n",
    "\n",
    "lstm.backward(dnext_h)\n",
    "dx, dh0, dWx, dWh, db = lstm.grad['dx'], lstm.grad['dh0'], lstm.grad['dWx'], lstm.grad['dWh'], lstm.grad['db']\n",
    "\n",
    "f = lambda _: lstm.forward(x, h0)\n",
    "\n",
    "dx_num = grad_check(f, x, dnext_h)\n",
    "dh0_num = grad_check(f, h0, dnext_h)\n",
    "dWx_num = grad_check(f, lstm.Wx, dnext_h)\n",
    "dWh_num = grad_check(f, lstm.Wh, dnext_h)\n",
    "db_num = grad_check(f, lstm.b, dnext_h)\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dh0 error: ', rel_error(dh0_num, dh0))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRULayer: Forward step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, H = 3, 4, 5\n",
    "gru = GRULayer(4, 5)\n",
    "x = np.linspace(-0.4, 1.2, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.3, 0.7, num=N*H).reshape(N, H)\n",
    "gru.Wx = np.linspace(-2.1, 1.3, num=2*D*H).reshape(D, 2 * H)\n",
    "gru.Wh = np.linspace(-0.7, 2.2, num=2*H*H).reshape(H, 2 * H)\n",
    "gru.b = np.linspace(0.3, 0.7, num=2*H)\n",
    "gru.Wxi = np.linspace(-1.8, 2.1, num=D*H).reshape(D, H)\n",
    "gru.Whi = np.linspace(-0.9, 1.6, num=H*H).reshape(H, H)\n",
    "gru.bi = np.linspace(0.1, 0.9, num=H)\n",
    "\n",
    "next_h, _ = gru.forward_step(x, prev_h)\n",
    "\n",
    "expected_next_h = np.asarray([\n",
    "    [-0.0999449,  -0.03125071,  0.03639522,  0.10290262,  0.16817868],\n",
    "    [ 0.2976273,   0.36884449,  0.3992976,   0.42559245,  0.45798687],\n",
    "    [ 0.49371886,  0.70402669,  0.70335355,  0.71138395,  0.7425779 ]])\n",
    "\n",
    "print('next_h error: ', rel_error(expected_next_h, next_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRULayer: Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, H, T = 2, 5, 4, 3\n",
    "gru = GRULayer(5, 4)\n",
    "x = np.linspace(-0.4, 0.6, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.4, 0.8, num=N*H).reshape(N, H)\n",
    "gru.Wx = np.linspace(-0.2, 0.9, num=2*D*H).reshape(D, 2 * H)\n",
    "gru.Wh = np.linspace(-0.3, 0.6, num=2*H*H).reshape(H, 2 * H)\n",
    "gru.b = np.linspace(0.2, 0.7, num=2*H)\n",
    "gru.Wxi = np.linspace(-0.4, 1.6, num=D*H).reshape(D, H)\n",
    "gru.Whi = np.linspace(-0.7, 0.4, num=H*H).reshape(H, H)\n",
    "gru.bi = np.linspace(0.4, 0.9, num=H)\n",
    "\n",
    "h = gru.forward(x, h0)\n",
    "\n",
    "expected_h = np.asarray([\n",
    " [[-0.19332136, -0.12098466, -0.0478229,   0.02618775],\n",
    "  [ 0.03427635,  0.09687263,  0.15884181,  0.22017801],\n",
    "  [ 0.22173995,  0.30237624,  0.36888384,  0.42432841]],\n",
    "\n",
    " [[ 0.3842619,   0.55153297,  0.69594892,  0.83361145],\n",
    "  [ 0.48151744,  0.63219579,  0.74877489,  0.85939455],\n",
    "  [ 0.56501369,  0.69358245,  0.78641933,  0.87723583]]])\n",
    "\n",
    "print('h error: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRULayer: Backward Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(145)\n",
    "\n",
    "N, D, H = 4, 5, 6\n",
    "gru = GRULayer(5, 6)\n",
    "x = np.random.randn(N, D)\n",
    "prev_h = np.random.randn(N, H)\n",
    "gru.Wx = np.random.randn(D, 2 * H)\n",
    "gru.Wh = np.random.randn(H, 2 * H)\n",
    "gru.b = np.random.randn(2 * H)\n",
    "gru.Wxi = np.random.randn(D, H)\n",
    "gru.Whi = np.random.randn(H, H)\n",
    "gru.bi = np.random.randn(H)\n",
    "\n",
    "next_h, cache = gru.forward_step(x, prev_h)\n",
    "\n",
    "dnext_h = np.random.randn(*next_h.shape)\n",
    "\n",
    "f = lambda _: gru.forward_step(x, prev_h)[0]\n",
    "\n",
    "\n",
    "dx_num = grad_check(f, x, dnext_h)\n",
    "dprev_h_num = grad_check(f, prev_h, dnext_h)\n",
    "dWx_num = grad_check(f, gru.Wx, dnext_h)\n",
    "dWh_num = grad_check(f, gru.Wh, dnext_h)\n",
    "db_num = grad_check(f, gru.b, dnext_h)\n",
    "dWxi_num = grad_check(f, gru.Wxi, dnext_h)\n",
    "dWhi_num = grad_check(f, gru.Whi, dnext_h)\n",
    "dbi_num = grad_check(f, gru.bi, dnext_h)\n",
    "\n",
    "dx, dprev_h, dWx, dWh, db, dWxi, dWhi, dbi = gru.backward_step(dnext_h, cache)\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dprev_h error: ', rel_error(dprev_h_num, dprev_h))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))\n",
    "print('dWxi error: ', rel_error(dWxi_num, dWxi))\n",
    "print('dWhi error: ', rel_error(dWhi_num, dWhi))\n",
    "print('dbi error: ', rel_error(dbi_num, dbi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRULayer: Backward Pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(145)\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 6\n",
    "gru = GRULayer(3, 6)\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "gru.Wx = np.random.randn(D, 2 * H)\n",
    "gru.Wh = np.random.randn(H, 2 * H)\n",
    "gru.b = np.random.randn(2 * H)\n",
    "gru.Wxi = np.random.randn(D, H)\n",
    "gru.Whi = np.random.randn(H, H)\n",
    "gru.bi = np.random.randn(H)\n",
    "\n",
    "out = gru.forward(x, h0)\n",
    "\n",
    "dnext_h = np.random.randn(*out.shape)\n",
    "\n",
    "gru.backward(dnext_h)\n",
    "\n",
    "dx, dh0, dWx, dWh, db, dWxi, dWhi, dbi = gru.grad['dx'], gru.grad['dh0'], gru.grad['dWx'], \\\n",
    "                                         gru.grad['dWh'], gru.grad['db'], \\\n",
    "                                         gru.grad['dWxi'], gru.grad['dWhi'], gru.grad['dbi']\n",
    "\n",
    "f = lambda _: gru.forward(x, h0)\n",
    "\n",
    "dx_num = grad_check(f, x, dnext_h)\n",
    "dh0_num = grad_check(f, h0, dnext_h)\n",
    "dWx_num = grad_check(f, gru.Wx, dnext_h)\n",
    "dWh_num = grad_check(f, gru.Wh, dnext_h)\n",
    "db_num = grad_check(f, gru.b, dnext_h)\n",
    "dWxi_num = grad_check(f, gru.Wxi, dnext_h)\n",
    "dWhi_num = grad_check(f, gru.Whi, dnext_h)\n",
    "dbi_num = grad_check(f, gru.bi, dnext_h)\n",
    "\n",
    "\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dh0 error: ', rel_error(dh0_num, dh0))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))\n",
    "print('dWxi error: ', rel_error(dWxi_num, dWxi))\n",
    "print('dWhi error: ', rel_error(dWhi_num, dWhi))\n",
    "print('dbi error: ', rel_error(dbi_num, dbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
